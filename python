importing the dependencies


[ ]
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

loading csv data to a pandas dataframe


[ ]
heart_data=pd.read_csv('/content/heart.csv')
print first 5 rows of the data set


[ ]
heart_data.head()

print last 5 rows of the dataset


[ ]
heart_data.tail()

number of rows and columns in the dataset


[ ]
heart_data.shape
(1025, 14)
Getting some info about the data


[ ]
heart_data.info()
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 1025 entries, 0 to 1024
Data columns (total 14 columns):
 #   Column    Non-Null Count  Dtype  
---  ------    --------------  -----  
 0   age       1025 non-null   int64  
 1   sex       1025 non-null   int64  
 2   cp        1025 non-null   int64  
 3   trestbps  1025 non-null   int64  
 4   chol      1025 non-null   int64  
 5   fbs       1025 non-null   int64  
 6   restecg   1025 non-null   int64  
 7   thalach   1025 non-null   int64  
 8   exang     1025 non-null   int64  
 9   oldpeak   1025 non-null   float64
 10  slope     1025 non-null   int64  
 11  ca        1025 non-null   int64  
 12  thal      1025 non-null   int64  
 13  target    1025 non-null   int64  
dtypes: float64(1), int64(13)
memory usage: 112.2 KB

[ ]
#checking for missing values
heart_data.isnull().sum()

statistical measures about the data


[ ]
heart_data.describe()

checking the distribution of the target variable


[ ]
heart_data['target'].value_counts()

1-->defective heart 0-->healthy heart

splitting the features and target


[ ]
X=heart_data.drop(columns='target',axis=1)
Y=heart_data['target']

print(X)
      age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \
0      52    1   0       125   212    0        1      168      0      1.0   
1      53    1   0       140   203    1        0      155      1      3.1   
2      70    1   0       145   174    0        1      125      1      2.6   
3      61    1   0       148   203    0        1      161      0      0.0   
4      62    0   0       138   294    1        1      106      0      1.9   
...   ...  ...  ..       ...   ...  ...      ...      ...    ...      ...   
1020   59    1   1       140   221    0        1      164      1      0.0   
1021   60    1   0       125   258    0        0      141      1      2.8   
1022   47    1   0       110   275    0        0      118      1      1.0   
1023   50    0   0       110   254    0        0      159      0      0.0   
1024   54    1   0       120   188    0        1      113      0      1.4   

      slope  ca  thal  
0         2   2     3  
1         0   0     3  
2         0   0     3  
3         2   1     3  
4         1   3     2  
...     ...  ..   ...  
1020      2   0     2  
1021      1   1     3  
1022      1   1     2  
1023      2   0     2  
1024      1   1     3  

[1025 rows x 13 columns]
splitting the data into training data and test data


[ ]
X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2,stratify=Y,random_state=2)
print(X.shape,X_train.shape,X_test.shape)
(1025, 13) (820, 13) (205, 13)
Model training


[ ]
model=LogisticRegression()

[ ]
#training the logisticregression model with training data
model.fit(X_train,Y_train)

model evaluation

Accuracy Score of training data


[ ]
X_train_prediction=model.predict(X_train)
training_data_accuracy=accuracy_score(X_train_prediction,Y_train)

[ ]
print('Accuracy on training data:',training_data_accuracy)
Accuracy on training data: 0.8524390243902439

[ ]
X_test_prediction=model.predict(X_test)
test_data_accuracy=accuracy_score(X_test_prediction,Y_test)


print('Accuracy on test data:',test_data_accuracy)
Accuracy on test data: 0.8048780487804879
building the predictive system


[ ]
input_data=(41,0,1,130,204,0,0,172,0,1.4,2,0,2)

#change the input data into numpy array

[ ]
input_data_as_numpy_array=np.asarray(input_data)

#reshape the numpy array as we are predicting for only on instance

input_data_reshaped=input_data_as_numpy_array.reshape(1,-1)

prediction=model.predict(input_data_reshaped)
print(prediction)
[1]
/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names
  warnings.warn(

[ ]
if (prediction[0]==0):
  print("The person does not have the heart disease")

else:
  print("The person has heart disease")


The person has heart disease


